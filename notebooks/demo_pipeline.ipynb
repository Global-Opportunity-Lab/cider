{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9caa59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c509d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up openjdk paths for spark\n",
    "\n",
    "# for MacOS\n",
    "import os\n",
    "os.environ['JAVA_HOME'] = '/Library/Java/JavaVirtualMachines/openjdk-17.jdk/Contents/Home'\n",
    "os.environ['PATH'] = f\"{os.environ['JAVA_HOME']}/bin:{os.environ['PATH']}\"\n",
    "\n",
    "# Set up logging\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b2f531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from cider.schemas import (\n",
    "    CallDataRecordData,\n",
    "    AntennaData,\n",
    "    MobileMoneyTransactionData,\n",
    ")\n",
    "from cider.utils import generate_all_synthetic_data, validate_dataframe, generate_synthetic_shapefile\n",
    "from cider.homelocation.schemas import GeographicUnit, GetHomeLocationAlgorithm\n",
    "from cider.homelocation.core import get_home_locations\n",
    "from cider.homelocation.plotting import make_location_map\n",
    "\n",
    "from cider.featurizer.core import preprocess_data, featurize_all_data\n",
    "from cider.featurizer.dependencies import get_static_diagnostic_statistics, get_timeseries_diagnostic_statistics\n",
    "from cider.featurizer.plotting import plot_timeseries_diagnostics\n",
    "\n",
    "from cider.validation_metrics.core import (\n",
    "    compute_auc_roc_precision_recall_with_percentile_grid, \n",
    "    compute_utility_grid, \n",
    "    calculate_optimal_utility_and_cash_transfer_size_table,\n",
    "    calculate_rank_residuals_by_characteristic,\n",
    "    combine_tables_on_characteristic,)\n",
    "from cider.validation_metrics.plotting import (\n",
    "    plot_roc_precision_recall_curves,\n",
    "    plot_utility_values,\n",
    "    plot_rank_residual_distributions_per_characteristic_value,\n",
    "    plot_all_fairness_metrics_per_characteristic_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552b065e",
   "metadata": {},
   "source": [
    "# Step 1: Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b6f767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set vars\n",
    "num_data_points = 2000\n",
    "num_unique_antenna_ids = 100\n",
    "num_regions = 10\n",
    "random_seed = 42\n",
    "\n",
    "# Generate synthetic data OR load your own data here\n",
    "synthetic_data = generate_all_synthetic_data(\n",
    "    num_data_points=num_data_points,\n",
    "    num_unique_antenna_ids=num_unique_antenna_ids,\n",
    "    random_seed=random_seed,\n",
    ")\n",
    "\n",
    "shapefile_gdf = generate_synthetic_shapefile(\n",
    "    antenna_df=synthetic_data[AntennaData],\n",
    "    num_regions=num_regions,\n",
    "    random_seed=random_seed,\n",
    ")\n",
    "\n",
    "# Validate data\n",
    "for data_schema, data_df in synthetic_data.items():\n",
    "    validate_dataframe(data_df, data_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1563754b",
   "metadata": {},
   "source": [
    "# Step 2: Infer transactions around home antenna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f721a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for home location inference\n",
    "geographic_unit = GeographicUnit.SHAPEFILE\n",
    "algorithm = GetHomeLocationAlgorithm.COUNT_DAYS\n",
    "\n",
    "# Infer home locations\n",
    "homes_df = get_home_locations(\n",
    "    cdr_data=synthetic_data[CallDataRecordData],\n",
    "    antenna_data=synthetic_data[AntennaData],\n",
    "    shapefile_data=shapefile_gdf,\n",
    "    geographic_unit=geographic_unit,\n",
    "    algorithm=algorithm,\n",
    "    additional_columns_to_keep=[],\n",
    ")\n",
    "\n",
    "# Merge home locations with antenna data for plotting\n",
    "homes_with_antenna_df = homes_df.merge(\n",
    "    synthetic_data[AntennaData],\n",
    "    left_on=\"caller_antenna_id\",\n",
    "    right_on=\"antenna_id\",\n",
    "    how=\"left\")\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "homes_with_antenna_gdf = gpd.GeoDataFrame(\n",
    "    homes_with_antenna_df,\n",
    "    geometry=gpd.points_from_xy(\n",
    "        x=homes_with_antenna_df['longitude'],\n",
    "        y=homes_with_antenna_df['latitude'])\n",
    ").set_crs(epsg=4326)\n",
    "\n",
    "# Plot home locations\n",
    "make_location_map(\n",
    "    inferred_home_locations=homes_with_antenna_gdf,\n",
    "    boundaries_shapefile=shapefile_gdf,\n",
    "    column_to_plot_label=\"caller_antenna_id\",\n",
    "    column_to_plot_markersize=algorithm.value,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d307301",
   "metadata": {},
   "source": [
    "# Step 3: Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5297b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for preprocessing\n",
    "filter_start_date = datetime.strptime(\"2022-01-05\", \"%Y-%m-%d\")\n",
    "filter_end_date = datetime.strptime(\"2025-01-25\", \"%Y-%m-%d\")\n",
    "spammer_threshold = 1.75\n",
    "outlier_day_z_score_threshold = 2.0\n",
    "\n",
    "# Preprocess data: filtering, spammer removal, outlier day removal\n",
    "preprocessed_data = preprocess_data(\n",
    "    data_dict=synthetic_data,\n",
    "    filter_start_date=filter_start_date,\n",
    "    filter_end_date=filter_end_date,\n",
    "    spammer_threshold=spammer_threshold,\n",
    "    outlier_day_z_score_threshold=outlier_day_z_score_threshold,\n",
    ")\n",
    "\n",
    "\n",
    "# Get diagnostics for preprocessed data\n",
    "static_diagnostics = {}\n",
    "timeseries_diagnostics = {}\n",
    "for data_schema, data_df in preprocessed_data.items():\n",
    "    static_diagnostics[data_schema] = get_static_diagnostic_statistics(data_df)\n",
    "    print(static_diagnostics[data_schema])\n",
    "\n",
    "    timeseries_diagnostics[data_schema] = get_timeseries_diagnostic_statistics(data_df)\n",
    "    fig = plot_timeseries_diagnostics(\n",
    "        timeseries_diagnostics[data_schema],\n",
    "        value_column=\"num_unique_callers\",\n",
    "        groupby_column=\"transaction_type\" if data_schema in [CallDataRecordData, MobileMoneyTransactionData] else None,\n",
    "        plot_title=f\"Timeseries Diagnostics for {data_schema.__name__}\",\n",
    "    )\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6932fa",
   "metadata": {},
   "source": [
    "# Step 4: Featurize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6b9d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for featurization\n",
    "max_wait_for_convo_in_seconds = 3600\n",
    "pareto_threshold = 0.8\n",
    "\n",
    "# Prepare antenna_data\n",
    "antenna_gdf = gpd.GeoDataFrame(\n",
    "    synthetic_data[AntennaData],\n",
    "    geometry=gpd.points_from_xy(\n",
    "        x=synthetic_data[AntennaData]['longitude'],\n",
    "        y=synthetic_data[AntennaData]['latitude'])\n",
    ").set_crs(epsg=4326)\n",
    "antennas_merged_shp = gpd.sjoin(antenna_gdf, shapefile_gdf, how='left', predicate='within')[['antenna_id', 'region']]\n",
    "antennas_merged_shp.region.fillna('Unknown', inplace=True)\n",
    "antennas_df = antennas_merged_shp.merge(\n",
    "    synthetic_data[AntennaData],\n",
    "    on=\"antenna_id\")\n",
    "\n",
    "preprocessed_data[AntennaData] = antennas_df\n",
    "\n",
    "# Featurize all data\n",
    "features_df = featurize_all_data(\n",
    "    preprocessed_data=preprocessed_data,\n",
    "    max_wait_for_convo_in_seconds=max_wait_for_convo_in_seconds,\n",
    "    pareto_threshold=pareto_threshold,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b3cc62",
   "metadata": {},
   "source": [
    "# Step 6: Fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851199f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features_df for modeling or analysis\n",
    "features_df_clean = features_df.dropna(axis=1, how='any')\n",
    "\n",
    "# Make fake groundtruth consumption values\n",
    "groundtruth_consumption = np.random.rand(len(features_df_clean)) * 10\n",
    "weights = np.random.randint(10, 100, size=len(features_df_clean))\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test, weights_train, weights_test = train_test_split(features_df_clean, groundtruth_consumption, weights, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train.drop(columns=\"caller_id\"), y_train)\n",
    "\n",
    "# Get predictions\n",
    "y_pred_train = model.predict(X_train.drop(columns=\"caller_id\"))\n",
    "y_pred_test = model.predict(X_test.drop(columns=\"caller_id\"))\n",
    "\n",
    "# Prepare data for validation metrics\n",
    "consumption_data = pd.DataFrame({\n",
    "    'household_id': X_test['caller_id'],\n",
    "    'groundtruth_consumption': y_test,\n",
    "    'weight': weights_test,\n",
    "    'proxy_consumption': y_pred_test,\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268852bd",
   "metadata": {},
   "source": [
    "# Step 7: Evaluate model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79204db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_groundtruth_percentile = 20  # Bottom 20% are considered \"low-income\"\n",
    "\n",
    "# Simulate additional characteristics for fairness analysis\n",
    "np.random.seed(42)\n",
    "allowed_gender_values = {'male', 'female', 'other'}\n",
    "consumption_data_w_gender = consumption_data.copy()\n",
    "consumption_data_w_gender['characteristic'] = np.random.choice(list(allowed_gender_values), size=len(consumption_data_w_gender))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1591ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# AUC ROC\n",
    "auc_roc_precision_recall_df = compute_auc_roc_precision_recall_with_percentile_grid(\n",
    "    consumption_data,\n",
    "    fixed_groundtruth_percentile,\n",
    "    100)\n",
    "\n",
    "# Plot ROC Curve\n",
    "fig, ax = plot_roc_precision_recall_curves(auc_roc_precision_recall_df, fixed_groundtruth_percentile)\n",
    "fig  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1868c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute utility grid\n",
    "cash_transfer_at_ubi_rate = 0.01 * consumption_data['weight'].sum()\n",
    "utility_grid_df = compute_utility_grid(\n",
    "    consumption_data,\n",
    "    cash_transfer_amount=cash_transfer_at_ubi_rate,\n",
    "    num_grid_points=99,\n",
    "    constant_relative_risk_aversion=3.0)\n",
    "\n",
    "# Calculate optimal utility and cash transfer size table\n",
    "optimal_utility_df = calculate_optimal_utility_and_cash_transfer_size_table(\n",
    "    consumption_data,\n",
    "    cash_transfer_amount=cash_transfer_at_ubi_rate,\n",
    "    num_grid_points=10,\n",
    "    constant_relative_risk_aversion=3.0\n",
    ")\n",
    "\n",
    "# Plot utility values\n",
    "fig, ax = plot_utility_values(\n",
    "    utility_grid_df, \n",
    "    optimal_utility_df.loc[\"proxy_consumption\", \"optimal_population_percentile\"],\n",
    "    optimal_utility_df.loc[\"proxy_consumption\", \"maximum_utility\"],\n",
    "    cash_transfer_at_ubi_rate, 3)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3f51e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank residuals per characteristic\n",
    "rank_residual_df = calculate_rank_residuals_by_characteristic(\n",
    "    consumption_data_w_gender)\n",
    "\n",
    "# Plot rank residual distributions per characteristic value\n",
    "fig, ax = plot_rank_residual_distributions_per_characteristic_value(rank_residual_df, \"Gender\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513574b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute all other fairness metrics per characteristic value\n",
    "combined_results, statistics = combine_tables_on_characteristic(\n",
    "    consumption_data_w_gender,\n",
    "    50\n",
    ")\n",
    "\n",
    "# Plot all fairness metrics per characteristic value\n",
    "fig, ax = plot_all_fairness_metrics_per_characteristic_value(combined_results, statistics, \"Gender\", color=\"blue\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b78900",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cider",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
